<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SCFlow2: Plug-and-Play Object Pose Refiner with Shape-Constraint Scene Flow</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.onload = function() {
      var videos = document.getElementsByTagName('video');
      for (var i = 0; i < videos.length; i++) {
        videos[i].setAttribute('preload', 'auto');
      }
    }
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SCFlow2: Plug-and-Play Object Pose Refiner with Shape-Constraint Scene Flow.</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?user=289PvugAAAAJ&hl=zh-CN">Qingyuan Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=_SKooBYAAAAJ&hl=zh-CN">Rui Song</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=Ccu3-acAAAAJ&view_op=list_works&sortby=pubdate">Jiaojiao Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=hpt1ehgAAAAJ&hl=zh-CN">Kerui Cheng</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=kW1QrJYAAAAJ&hl=en">David Ferstl</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=dhmdaoQAAAAJ&hl=en">Yinlin Hu</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>State Key Laboratory of ISN, Xidian University</span>
            <span class="author-block"><sup>2</sup>Taiyuan University of Technology</span>
            <span class="author-block"><sup>3</sup>MagicLeap</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/xxxx.xxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/xxxx.xxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/W-QY/SCFlow2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce SCFlow2, a plug-and-play refinement framework for 6D object pose estimation. 
            Most recent 6D object pose methods rely on refinement to get accurate results. However, most 
            existing refinements either suffer from noises in establishing correspondences, or rely on 
            retraining for novel objects. SCFlow2 is based on the SCFlow model designed for iterative RGB 
            refinement with shape constraint, but formulates the additional depth as a regularization in 
            the iteration via 3D scene flow for RGBD frames. The key design of SCFlow2 is an introduction 
            of geometry constraints into the training of recurrent match network, by combining the rigid-motion 
            embeddings in 3D scene flow and 3D shape prior of the target. We train the refinement network on a 
            combination of dataset Objaverse, GSO and ShapeNet, and demonstrate on BOP datasets with novel objects 
            that, after using our method, the result of most state-of-the-art methods improves significantly, 
            without any retraining or fine-tuning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>


<style>
  .video-table {
    width: 100%;
    border-collapse: collapse;
  }
  .video-table td {
    padding: 10px;
    text-align: center !important; 
    vertical-align: middle; /* 垂直居中 */
    border: 1px solid gray;
    
  }
  .video-table video {
    /* width: 100%;
    height: auto; */
    height: 300px;
    width: auto;
  }
  .label-ours {
    color: lime; /* 预定义的鲜艳绿色 */
    font-size: 12px;
    font-weight: bold;
  
  }

  .label-gt {
    color: blue;
    font-size: 12px;
    font-weight: bold;
  }
  a[href="https://rgbinhandscanning.github.io/"],
  a[href="https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/"],
  a[href="https://www.magicleap.com/magic-leap-2"] {
    text-decoration: underline;
  }
</style>



<section class="section">
  <div class="container is-max-desktop">
    Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results on YCB-V dataset</h2>
      </div>

    </div>
    <div class="content has-text-justified">
      <p>
        The video shows the comparison before and after we refine the coarse pose provided by <a href="https://evinpinar.github.io/foundpose/">FoundPose</a>.
      </p>
    </div>
<table class="video-table">
  <!-- <tr>
    <td><strong><a href="https://evinpinar.github.io/foundpose/">FoundPose</a></strong></td>
    <td><strong>Refined</strong></td>
    <td><strong>GT</strong></td>
  </tr> -->
  <tr>
    <!-- <td><video src="./static/videos/ycbv/ycbv_54_foundpose_init.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/ycbv/ycbv_54_foundpose_refined.mp4" autoplay muted loop playsinline></video></td>  
    <td><video src="./static/videos/ycbv/ycbv_54_foundpose_gt.mp4" autoplay muted loop playsinline></video></td>  -->
    <td><video src="./static/videos/ycbv_48_cat.mp4" autoplay muted loop playsinline></video></td>
  </tr>
  <tr>
    <!-- <td><video src="./static/videos/ycbv/ycbv_48_foundpose_init.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/ycbv/ycbv_48_foundpose_refined.mp4" autoplay muted loop playsinline></video></td>  
    <td><video src="./static/videos/ycbv/ycbv_48_foundpose_gt.mp4" autoplay muted loop playsinline></video></td>  -->
    <td><video src="./static/videos/ycbv_54_cat.mp4" autoplay muted loop playsinline></video></td>
  </tr>
  <tr>
    <!-- <td><video src="./static/videos/ycbv/ycbv_58_foundpose_init.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/ycbv/ycbv_58_foundpose_refined.mp4" autoplay muted loop playsinline></video></td>  
    <td><video src="./static/videos/ycbv/ycbv_58_foundpose_gt.mp4" autoplay muted loop playsinline></video></td>  -->
    <td><video src="./static/videos/ycbv_58_cat.mp4" autoplay muted loop playsinline></video></td>
  </tr>
  <tr>
    <!-- <td><video src="./static/videos/ycbv/ycbv_59_foundpose_init.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/ycbv/ycbv_59_foundpose_refined.mp4" autoplay muted loop playsinline></video></td>  
    <td><video src="./static/videos/ycbv/ycbv_59_foundpose_gt.mp4" autoplay muted loop playsinline></video></td>  -->
    <td><video src="./static/videos/ycbv_59_cat.mp4" autoplay muted loop playsinline></video></td>
  </tr>
</table>

<div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Robustness to initial pose jitter</h2>
      </div>

    </div>
    <div class="content has-text-justified">
      <p>
        We add random rotation and translation noise to GT pose as the initialization and optimize the pose. Our method is robust to inaccurate initialization.
      </p>
    </div>
<table class="video-table">
  <tr>
    <td style="width: 100px;"><strong>Dataset Name </strong></td>
    <td><strong>Results comparison</strong></td>
    <!-- <td><strong>Refined</strong></td> -->
    <!-- <td><strong>Initialization</strong></td>
    <td><strong>Refined</strong></td> -->
  </tr>
  <tr>
    <td><strong>T-LESS </strong></td>
    <td><video src="./static/videos/tless_jtrefined.mp4" autoplay muted loop playsinline></video></td>
    <!-- <td><video src="./static/videos/ycbv/ycbv_50_refined.mp4" autoplay muted loop playsinline></video></td>   -->
    <!-- <td><video src="./static/videos/ycbv/ycbv_init_2.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/ycbv/ycbv_refined_2.mp4" autoplay muted loop playsinline></video></td> -->
  </tr>
  <tr>
    <td><strong>TUD-L </strong></td>
    <td><video src="./static/videos/tudl_jtrefined.mp4" autoplay muted loop playsinline></video></td>
    <!-- <td><video src="./static/videos/lmo/lmo_refined.mp4" autoplay muted loop playsinline></video></td>   -->
    <!-- <td><video src="./static/videos/lmo/lmo_init_2.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/lmo/lmo_refined_2.mp4" autoplay muted loop playsinline></video></td> -->
  </tr>
  <tr>
    <td><strong>YCB-V </strong></td>
    <td><video src="./static/videos/ycbv_jt_refined.mp4" autoplay muted loop playsinline></video></td>
    <!-- <td><video src="./static/videos/tudl/tudl_refined.mp4" autoplay muted loop playsinline></video></td>   -->
    <!-- <td><video src="./static/videos/tudl/tudl_init_2.mp4" autoplay muted loop playsinline></video></td>
    <td><video src="./static/videos/tudl/tudl_refined_2.mp4" autoplay muted loop playsinline></video></td> -->
  </tr>
</table>

<div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX: TODO: </h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    The webpage is adapted from  <a
    href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>.
  </div>

  </div>
</footer>

</body>
</html>
